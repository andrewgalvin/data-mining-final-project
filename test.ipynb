{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procedureApriori(T, minSupport):\n",
    "    candidateItemset = {}\n",
    "    # frequentItemset is used to keep a running list of all of the frequently occuring sets of data in the code\n",
    "    frequentItemset = []\n",
    "\n",
    "    # Generate K1 sets\n",
    "    for transaction in T:\n",
    "        for item in transaction:\n",
    "            if item in candidateItemset:\n",
    "                candidateItemset[item] += 1\n",
    "            else:\n",
    "                candidateItemset[item] = 1\n",
    "    # Reference used: https://stackoverflow.com/questions/58324419/how-do-i-remove-all-items-in-a-dictionary-with-a-value-less-than-a-variable\n",
    "    for key in list(candidateItemset):\n",
    "        if candidateItemset[key] < minSupport:\n",
    "            del candidateItemset[key]\n",
    "    frequentItemset = list(candidateItemset)\n",
    "    if len(candidateItemset) == 0:\n",
    "        return list(candidateItemset)\n",
    "    candidateItemset = {}\n",
    "    countCandidates = {}\n",
    "    # frequentItemset.sort()\n",
    "\n",
    "    # Generate K2 Sets\n",
    "    # Reference used: https://stackoverflow.com/questions/63970483/how-to-check-if-an-array-contains-all-the-elements-of-another-array-if-not-out\n",
    "    # Candidate Generation\n",
    "    for i in range(0, len(frequentItemset)):\n",
    "        for j in range(i + 1, len(frequentItemset)):\n",
    "            k2Set = []\n",
    "            if frequentItemset[i] < frequentItemset[j]:\n",
    "                currentKey = frequentItemset[i] + \" \" + frequentItemset[j]\n",
    "                k2Set.append(frequentItemset[i])\n",
    "                k2Set.append(frequentItemset[j])\n",
    "            else:\n",
    "                currentKey = frequentItemset[i] + \" \" + frequentItemset[j]\n",
    "                k2Set.append(frequentItemset[j])\n",
    "                k2Set.append(frequentItemset[i])\n",
    "            candidateItemset[currentKey] = k2Set\n",
    "            # Transaction Iteration\n",
    "            for transaction in T:\n",
    "                if (\n",
    "                    len(\n",
    "                        [\n",
    "                            h\n",
    "                            for h in candidateItemset[currentKey]\n",
    "                            if h not in transaction\n",
    "                        ]\n",
    "                    )\n",
    "                    == 0\n",
    "                ):\n",
    "                    if currentKey in countCandidates:\n",
    "                        countCandidates[currentKey] += 1\n",
    "                    else:\n",
    "                        countCandidates[currentKey] = 1\n",
    "    # Candidate Pruning\n",
    "    for key in list(candidateItemset):\n",
    "        if key in countCandidates:\n",
    "            if countCandidates[key] < minSupport:\n",
    "                del candidateItemset[key]\n",
    "                del countCandidates[key]\n",
    "            else:\n",
    "                frequentItemset.append(key)\n",
    "        else:\n",
    "            del candidateItemset[key]\n",
    "\n",
    "    if len(candidateItemset) == 0:\n",
    "        return frequentItemset\n",
    "    k = 3\n",
    "\n",
    "    while True:\n",
    "        countCandidates = {}\n",
    "        newCandidates = {}\n",
    "        currentSet = list(candidateItemset)\n",
    "        # Candidate Generation\n",
    "        for i in range(0, len(candidateItemset)):\n",
    "            for h in range(i + 1, len(candidateItemset)):\n",
    "                match = True\n",
    "                for x in range(0, len(currentSet[i]) - 2):\n",
    "                    if len(currentSet[i]) != len(currentSet[h]):\n",
    "                        continue\n",
    "                    if currentSet[i][x] != currentSet[h][x]:\n",
    "                        match = False\n",
    "                if match == True:\n",
    "                    newElement = (\n",
    "                        currentSet[i] + \" \" + currentSet[h][len(currentSet[h]) - 1]\n",
    "                    )\n",
    "                    if newElement not in newCandidates:\n",
    "                        L = candidateItemset[currentSet[i]]\n",
    "                        L.append(currentSet[h][len(currentSet[h]) - 1])\n",
    "                        newCandidates[newElement] = L\n",
    "\n",
    "        # Transaction Iteration\n",
    "        newCountCandidates = {}\n",
    "        for key in newCandidates:\n",
    "            for transaction in T:\n",
    "                if len([h for h in newCandidates[key] if h not in transaction]) == 0:\n",
    "                    if key in newCountCandidates:\n",
    "                        newCountCandidates[key] += 1\n",
    "                    else:\n",
    "                        newCountCandidates[key] = 1\n",
    "\n",
    "        # Candidate Pruning\n",
    "        for key in list(newCandidates):\n",
    "            if key in newCountCandidates:\n",
    "                if newCountCandidates[key] < minSupport:\n",
    "                    del newCandidates[key]\n",
    "                    del newCountCandidates[key]\n",
    "                else:\n",
    "                    frequentItemset.append(key)\n",
    "            else:\n",
    "                del newCandidates[key]\n",
    "\n",
    "        # If no candidates after pruning, return\n",
    "        if len(newCandidates) == 0:\n",
    "            return frequentItemset\n",
    "        candidateItemset = newCandidates\n",
    "\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emojiset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT maykahangtoran: We really made VP Leni Robr...</td>\n",
       "      <td>😭</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT DEATHBALL13: Meanwhile 🤡🤡Joey you’re hiding...</td>\n",
       "      <td>🤡🤡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT minimeuu: Já apanhaste COVID!? Me:não 😬 RT ...</td>\n",
       "      <td>😬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT sarinhaavps: Já apanhaste COVID!? Me:não 😬 ...</td>\n",
       "      <td>😬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT fann961: 7-day average daily Covid deaths p...</td>\n",
       "      <td>🇭🇰,🇺🇸,🇯🇵,🇬🇧,🇨🇦,🇦🇺,🇸🇬</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet              Emojiset\n",
       "0  RT maykahangtoran: We really made VP Leni Robr...                     😭\n",
       "1  RT DEATHBALL13: Meanwhile 🤡🤡Joey you’re hiding...                    🤡🤡\n",
       "2  RT minimeuu: Já apanhaste COVID!? Me:não 😬 RT ...                     😬\n",
       "3  RT sarinhaavps: Já apanhaste COVID!? Me:não 😬 ...                     😬\n",
       "4  RT fann961: 7-day average daily Covid deaths p...  🇭🇰,🇺🇸,🇯🇵,🇬🇧,🇨🇦,🇦🇺,🇸🇬"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"./data/covid.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emoji import UNICODE_EMOJI\n",
    "\n",
    "def extractEmojis(text):\n",
    "    emojis = []\n",
    "\n",
    "    if type(text) != str:\n",
    "        return []\n",
    "    \n",
    "    for word in text.split(\" \"):\n",
    "        if word in UNICODE_EMOJI['en']:\n",
    "            emojis.append(word)\n",
    "        else:\n",
    "            current_emoji = \"\"\n",
    "\n",
    "            for c in range(len(word)):\n",
    "                if word[c] in UNICODE_EMOJI['en']:\n",
    "                    current_emoji += word[c]\n",
    "\n",
    "            if current_emoji != \"\":\n",
    "                emojis.append(current_emoji)\n",
    "                current_emoji = \"\"\n",
    "\n",
    "    return emojis\n",
    "\n",
    "# UNICODE_EMOJI['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emojiset</th>\n",
       "      <th>extracted_emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT maykahangtoran: We really made VP Leni Robr...</td>\n",
       "      <td>😭</td>\n",
       "      <td>[😭]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT DEATHBALL13: Meanwhile 🤡🤡Joey you’re hiding...</td>\n",
       "      <td>🤡🤡</td>\n",
       "      <td>[🤡🤡]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT minimeuu: Já apanhaste COVID!? Me:não 😬 RT ...</td>\n",
       "      <td>😬</td>\n",
       "      <td>[😬]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT sarinhaavps: Já apanhaste COVID!? Me:não 😬 ...</td>\n",
       "      <td>😬</td>\n",
       "      <td>[😬]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT fann961: 7-day average daily Covid deaths p...</td>\n",
       "      <td>🇭🇰,🇺🇸,🇯🇵,🇬🇧,🇨🇦,🇦🇺,🇸🇬</td>\n",
       "      <td>[🇭🇰, 🇺🇸, 🇯🇵, 🇬🇧, 🇨🇦, 🇦🇺, 🇸🇬]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet              Emojiset  \\\n",
       "0  RT maykahangtoran: We really made VP Leni Robr...                     😭   \n",
       "1  RT DEATHBALL13: Meanwhile 🤡🤡Joey you’re hiding...                    🤡🤡   \n",
       "2  RT minimeuu: Já apanhaste COVID!? Me:não 😬 RT ...                     😬   \n",
       "3  RT sarinhaavps: Já apanhaste COVID!? Me:não 😬 ...                     😬   \n",
       "4  RT fann961: 7-day average daily Covid deaths p...  🇭🇰,🇺🇸,🇯🇵,🇬🇧,🇨🇦,🇦🇺,🇸🇬   \n",
       "\n",
       "               extracted_emojis  \n",
       "0                           [😭]  \n",
       "1                          [🤡🤡]  \n",
       "2                           [😬]  \n",
       "3                           [😬]  \n",
       "4  [🇭🇰, 🇺🇸, 🇯🇵, 🇬🇧, 🇨🇦, 🇦🇺, 🇸🇬]  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['extracted_emojis'] = data['Tweet'].apply(extractEmojis)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              [😭]\n",
       "1                             [🤡🤡]\n",
       "2                              [😬]\n",
       "3                              [😬]\n",
       "4     [🇭🇰, 🇺🇸, 🇯🇵, 🇬🇧, 🇨🇦, 🇦🇺, 🇸🇬]\n",
       "5                              [😅]\n",
       "6                           [🕯, 🕯]\n",
       "7                           [🤣🤣🤣🤣]\n",
       "8                              [🗣]\n",
       "9                          [😡⬇, 😕]\n",
       "10                             [🤬]\n",
       "11                             [😭]\n",
       "12                      [🪙🙏, 🙏, 🪙]\n",
       "13                             [😭]\n",
       "14                          [🤣🤣🤣🤣]\n",
       "15                             [▶]\n",
       "16                      [🦠, 💉, 🙌🏻]\n",
       "17                          [🤣🤣🤣🤣]\n",
       "18                            [☝🏻]\n",
       "19                         [😡⬇, 😕]\n",
       "20                        [🤦♀🤦♀🤦♀]\n",
       "21                          [🤧, 💚]\n",
       "22                             [💡]\n",
       "23                         [🚨, 🤬🤮]\n",
       "24                     [🔬, ➡️, ✍️]\n",
       "25                             [🤮]\n",
       "26                          [🌞, 😷]\n",
       "27                            [👍🏼]\n",
       "28                            [🖐️]\n",
       "29                             [🤣]\n",
       "30                            [😭😭]\n",
       "31                             [😭]\n",
       "32                            [💉💉]\n",
       "33                          [💕, 😃]\n",
       "34                             [🤔]\n",
       "35                             [😭]\n",
       "36                             [😭]\n",
       "37                             [😓]\n",
       "38                 [👇, 👉, 👉, 👉, 🏥]\n",
       "39                             [🤡]\n",
       "40                          [🤣🤣🤣🤣]\n",
       "41                           [😭🙏🏻]\n",
       "42                             [💉]\n",
       "43                             [😍]\n",
       "44                            [🙏🏻]\n",
       "45                            [📄💉]\n",
       "46                             [😍]\n",
       "47                         [🤷🏻‍♂️]\n",
       "48                 [👇, 👉, 👉, 👉, 🏥]\n",
       "49                     [🔬, ➡️, ✍️]\n",
       "Name: extracted_emojis, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputList = data['extracted_emojis']\n",
    "inputList.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "setSup = 1\n",
    "# inputList = []\n",
    "# with open(\"./bread.csv\", newline=\"\", encoding=\"utf8\") as inputFile:\n",
    "#     reader = csv.reader(inputFile, delimiter=\",\")\n",
    "#     for row in reader:\n",
    "#         rowList = []\n",
    "#         for i in range(1, len(row)):\n",
    "#             if str(row[i]) != \"\":\n",
    "#                 rowList.append(str(row[i]))\n",
    "#         inputList.append(rowList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                [😭]\n",
       "1                               [🤡🤡]\n",
       "2                                [😬]\n",
       "3                                [😬]\n",
       "4       [🇭🇰, 🇺🇸, 🇯🇵, 🇬🇧, 🇨🇦, 🇦🇺, 🇸🇬]\n",
       "                    ...             \n",
       "996                             [💉💉]\n",
       "997                           [☑, ☑]\n",
       "998                              [👑]\n",
       "999                           [✅, 😷]\n",
       "1000                              []\n",
       "Name: extracted_emojis, Length: 1001, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = procedureApriori(inputList, setSup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_new_x = []\n",
    "new_x = []\n",
    "for i in x:\n",
    "    frozen_new_x.append(frozenset([k for k in i.split(\" \")]))\n",
    "    new_x.append([k for k in i.split(\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = pd.DataFrame()\n",
    "frequent_itemsets[\"itemsets\"] = frozen_new_x\n",
    "frequent_itemsets[\"support\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = association_rules(frequent_itemsets, support_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = []\n",
    "for l in range(len(r[\"antecedents\"].values)):\n",
    "    rules.append([list(r[\"antecedents\"][l])[0], list(r[\"consequents\"][l])[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['😭', '😭❤'], ['🇭🇰', '🇺🇸'], ['🇭🇰', '🇯🇵'], ['🇭🇰', '🇬🇧'], ['🇭🇰', '🇨🇦'], ['🇭🇰', '🇦🇺'], ['🇭🇰', '🇸🇬'], ['🇺🇸', '🇯🇵'], ['🇺🇸', '🇬🇧'], ['🇺🇸', '🇨🇦'], ['🇺🇸', '🇦🇺'], ['🇺🇸', '🇸🇬'], ['🇯🇵', '🇬🇧'], ['🇯🇵', '🇨🇦'], ['🇯🇵', '🇦🇺'], ['🇯🇵', '🇸🇬'], ['🇬🇧', '🇨🇦'], ['🇬🇧', '🇦🇺'], ['🇬🇧', '🇸🇬'], ['🇬🇧', '🚨'], ['🇬🇧', '🚫'], ['🇬🇧', '🇪🇺'], ['🇬🇧', '💥💥🚨'], ['🇬🇧', '🇨🇭'], ['🇨🇦', '🇦🇺'], ['🇨🇦', '🇸🇬'], ['🇦🇺', '🇸🇬'], ['😅', '🙏'], ['😅', '🤣🤣🤣'], ['😡⬇', '😕'], ['🪙🙏', '🙏'], ['🪙🙏', '🪙'], ['🙏', '🪙'], ['🙏', '😷'], ['🙏', '🙄'], ['🙏', '😉'], ['▶', '🔸'], ['🦠', '💉'], ['🦠', '🙌🏻'], ['🦠', '➡️'], ['🦠', '🤔'], ['🦠', '❤️'], ['🦠', '👍🏽'], ['🦠', '✔'], ['🦠', '🩹'], ['🦠', '➕'], ['🦠', '👉🏽'], ['💉', '🙌🏻'], ['💉', '➡️'], ['💉', '😷'], ['💉', '✅'], ['💉', '⚠'], ['💉', '❌'], ['💉', '👨🏻⚕'], ['💉', '🏡'], ['💉', '🌄'], ['💉', '🌬'], ['💉', '📍'], ['💉', '🧼'], ['💉', '🧪'], ['💉', '👇🚨'], ['💉', '🔵'], ['💉', '📌'], ['💉', '📊'], ['💉', '📅'], ['💉', '⤵️'], ['💉', '☎'], ['💉', '🚗'], ['🤧', '💚'], ['💚', '❌'], ['💚', '🇪🇸'], ['🚨', '🤬🤮'], ['🚨', '🧵'], ['🚨', '🚫'], ['🚨', '🇪🇺'], ['🚨', '💥💥🚨'], ['🚨', '🇨🇭'], ['🔬', '➡️'], ['🔬', '✍️'], ['🔬', '🧪'], ['🔬', '📈➡'], ['➡️', '✍️'], ['➡️', '✅'], ['➡️', '➡'], ['➡️', '😈'], ['➡️', '🌎'], ['➡️', '🌞⛱'], ['➡️', '🚨🚨'], ['➡️', '📊'], ['➡️', '⌛'], ['🌞', '😷'], ['😷', '✅'], ['😷', '😉'], ['😷', '⚠'], ['😷', '❌'], ['😷', '👨🏻⚕'], ['😷', '🏡'], ['😷', '🌄'], ['😷', '🌬'], ['😷', '👀'], ['😷', '🌎'], ['😷', '🔍'], ['😷', '🧼'], ['😷', '💧'], ['😷', '👨\\u200d👩\\u200d👧\\u200d👦'], ['😷', '📢'], ['😷', '🧴'], ['🤣', '🤔'], ['🤣', '🙄'], ['🤣', '🙈'], ['🤣', '🤗'], ['💉💉', '🇺🇦'], ['💉💉', '🇩🇪'], ['💕', '😃'], ['🤔', '👍🏽'], ['🤔', '✔'], ['🤔', '🩹'], ['🤔', '➕'], ['🤔', '👉🏽'], ['🤔', '🤗'], ['😓', '😔'], ['👇', '👉'], ['👇', '🏥'], ['👇', '➡'], ['👇', '🛑'], ['👇', '🐭'], ['👇', '📢'], ['👇', '🚑'], ['👇', '🟧'], ['👇', '🟣'], ['👇', '⚡'], ['👉', '🏥'], ['👉', '🔴'], ['👉', '🛑'], ['👉', '🏘️'], ['👉', '⏰'], ['👉', '⚠️'], ['👉', '🔔'], ['👉', '📌'], ['👉', '🟢'], ['👉', '🔄'], ['👉', '👩🏽\\u200d🌾'], ['🏥', '🔴'], ['🤡', '😭🤡'], ['😍', '🤫'], ['😍', '🤨'], ['✅', '🧡💙'], ['✅', '🧵'], ['✅', '➡'], ['✅', '😈'], ['✅', '📰'], ['✅', '👀'], ['✅', '🌎'], ['✅', '💢'], ['✅', '🤲'], ['✅', '📌'], ['✅', '🦠💉'], ['✅', '🧴'], ['✅', '⌛'], ['🧵', '🔺'], ['🧵', '➡'], ['🧵', '🦠💉'], ['🙄', '😉'], ['🗣️', '✍'], ['🗣️', '🇨🇲'], ['👍', '😑👎'], ['👍', '😊'], ['👍', '🤞'], ['🤞🏼', '🥴'], ['😎', '🙄🤔'], ['❤', '☺️'], ['✈️', '🛫'], ['😩😩', '😂'], ['😂', '🤦🤢🤮'], ['😂', '😌'], ['🔸', '🔴'], ['™', '😁'], ['💯', '💗'], ['😉', '🌸'], ['😉', '🎢'], ['⚠', '❌'], ['⚠', '👨🏻⚕'], ['⚠', '🏡'], ['⚠', '🌄'], ['⚠', '🌬'], ['❌', '👨🏻⚕'], ['❌', '🏡'], ['❌', '🌄'], ['❌', '🌬'], ['❌', '🇪🇸'], ['👨🏻⚕', '🏡'], ['👨🏻⚕', '🌄'], ['👨🏻⚕', '🌬'], ['🏡', '🌄'], ['🏡', '🌬'], ['🌄', '🌬'], ['🙏🏼', '💖'], ['🔴', '📌'], ['🔴', '🟢'], ['➡', '🛑'], ['➡', '🐭'], ['➡', '⬆'], ['➡', '🦠💉'], ['🤫', '😈'], ['🤫', '🤨'], ['😈', '🌎'], ['😈', '🌹'], ['😈', '⌛'], ['🙏🏽', '😥'], ['🙏🏽', '💪🏽'], ['😥', '💪🏽'], ['😀😀', '🥴😂😂'], ['🙂', '🤷\\u200d♀️'], ['🛑', '🟧'], ['🛑', '🟣'], ['🛑', '⚡'], ['🛑', '⬆'], ['🇧🇷', '😡🚩'], ['🏘️', '⏰'], ['🏘️', '⚠️'], ['⏰', '⚠️'], ['👀', '🌎'], ['👀', '🔍'], ['👀', '😑'], ['📍', '💢'], ['📍', '👉🏻👉🏻👉🏻👉🏻👉🏻👉🏻👉🏻👉🏻'], ['📍', '📅'], ['🌎', '🔍'], ['🌎', '⌛'], ['🤗🤲🤲', '🤒'], ['🧼', '💧'], ['🧼', '👨\\u200d👩\\u200d👧\\u200d👦'], ['🧼', '🧪'], ['🧼', '⤵️'], ['💧', '👨\\u200d👩\\u200d👧\\u200d👦'], ['👍🏽', '✔'], ['👍🏽', '🩹'], ['👍🏽', '➕'], ['👍🏽', '👉🏽'], ['✔', '🩹'], ['✔', '➕'], ['✔', '👉🏽'], ['🩹', '➕'], ['🩹', '👉🏽'], ['➕', '👉🏽'], ['😱', '🤯'], ['😊', '🤞'], ['🤯', '✨🥂'], ['📢', '🚑'], ['🧪', '📈➡'], ['🧪', '⤵️'], ['💢', '👉🏻👉🏻👉🏻👉🏻👉🏻👉🏻👉🏻👉🏻'], ['🚩🥰❤', '👇🏽'], ['🚩🥰❤', '🕊🚩💉'], ['👇🏽', '🕊🚩💉'], ['🏴\\U000e0067\\U000e0062\\U000e0065\\U000e006e\\U000e0067\\U000e007f', '🎥'], ['🇺🇦', '🇩🇪'], ['🇺🇦', '🇵🇹'], ['🇺🇦', '⬇'], ['🇺🇦', '🇫🇷'], ['🇺🇦', '♀'], ['🇺🇦', '♀️'], ['😆', '💸'], ['😆', '🔗'], ['⬇', '♀'], ['⬇', '♀️'], ['😳💥', '🔥💥'], ['🟧', '🟣'], ['🟧', '⚡'], ['🟣', '⚡'], ['🌸', '🎢'], ['🚫', '🇪🇺'], ['🚫', '💥💥🚨'], ['🚫', '🇨🇭'], ['🇪🇺', '💥💥🚨'], ['🇪🇺', '🇨🇭'], ['💥💥🚨', '🇨🇭'], ['📌', '🔥'], ['📌', '🟢'], ['🎈🎉🥰', '⬜⬜🟩⬜🟩'], ['🎈🎉🥰', '🟩🟩🟩🟩🟩'], ['⬜⬜🟩⬜🟩', '🟩🟩🟩🟩🟩'], ['💸', '🔗'], ['🔆', '♨'], ['🔆', '🔥'], ['♨', '🔥'], ['🤔🤔🤔', '🤕🤕🤕👋'], ['🪅🎊', '🤡🤡🤡'], ['🔹', '❗'], ['📈', '▫'], ['🔄', '👩🏽\\u200d🌾'], ['☎', '🚗'], ['7️⃣', '8️⃣'], ['♀', '♀️']]\n"
     ]
    }
   ],
   "source": [
    "new_rules = []\n",
    "\n",
    "for i in new_x:\n",
    "    for rule in rules:\n",
    "        before = rule[0]\n",
    "        after = rule[1]\n",
    "        before_idx = None\n",
    "        after_idx = None\n",
    "        for item in i:\n",
    "            if item == before:\n",
    "                if before_idx == None:\n",
    "                    before_idx = i.index(item)\n",
    "            elif item == after:\n",
    "                if after_idx == None:\n",
    "                    after_idx = i.index(item)\n",
    "        if before_idx != None and after_idx != None:\n",
    "            if before_idx < after_idx:\n",
    "                if rule not in new_rules:\n",
    "                    new_rules.append(rule)\n",
    "print(new_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
