{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procedureApriori(T, minSupport):\n",
    "    candidateItemset = {}\n",
    "    # frequentItemset is used to keep a running list of all of the frequently occuring sets of data in the code\n",
    "    frequentItemset = []\n",
    "    finalCounts = []\n",
    "    # Generate K1 sets\n",
    "    for transaction in T:\n",
    "        for item in transaction:\n",
    "            if item in candidateItemset:\n",
    "                candidateItemset[item] += 1\n",
    "            else:\n",
    "                candidateItemset[item] = 1\n",
    "    # Reference used: https://stackoverflow.com/questions/58324419/how-do-i-remove-all-items-in-a-dictionary-with-a-value-less-than-a-variable\n",
    "    for key in list(candidateItemset):\n",
    "        if candidateItemset[key] < minSupport:\n",
    "            del candidateItemset[key]\n",
    "    frequentItemset = list(candidateItemset)\n",
    "    if len(candidateItemset) == 0:\n",
    "        return list(candidateItemset), finalCounts\n",
    "    finalCounts += list(candidateItemset.values())\n",
    "    #print(candidateItemset)\n",
    "    candidateItemset = {}\n",
    "    countCandidates = {}\n",
    "    \n",
    "\n",
    "    # Generate K2 Sets\n",
    "    # Reference used: https://stackoverflow.com/questions/63970483/how-to-check-if-an-array-contains-all-the-elements-of-another-array-if-not-out\n",
    "    # Candidate Generation\n",
    "    for i in range(0, len(frequentItemset)):\n",
    "        for j in range(i + 1, len(frequentItemset)):\n",
    "            k2Set = []\n",
    "            if frequentItemset[i] < frequentItemset[j]:\n",
    "                currentKey = frequentItemset[i] + \" \" + frequentItemset[j]\n",
    "                k2Set.append(frequentItemset[i])\n",
    "                k2Set.append(frequentItemset[j])\n",
    "            else:\n",
    "                currentKey = frequentItemset[i] + \" \" + frequentItemset[j]\n",
    "                k2Set.append(frequentItemset[j])\n",
    "                k2Set.append(frequentItemset[i])\n",
    "            candidateItemset[currentKey] = k2Set\n",
    "            # Transaction Iteration\n",
    "            for transaction in T:\n",
    "                if (\n",
    "                    len(\n",
    "                        [\n",
    "                            h\n",
    "                            for h in candidateItemset[currentKey]\n",
    "                            if h not in transaction\n",
    "                        ]\n",
    "                    )\n",
    "                    == 0\n",
    "                ):\n",
    "                    if currentKey in countCandidates:\n",
    "                        countCandidates[currentKey] += 1\n",
    "                    else:\n",
    "                        countCandidates[currentKey] = 1\n",
    "    # Candidate Pruning\n",
    "    for key in list(candidateItemset):\n",
    "        if key in countCandidates:\n",
    "            if countCandidates[key] < minSupport:\n",
    "                del candidateItemset[key]\n",
    "                del countCandidates[key]\n",
    "            else:\n",
    "                frequentItemset.append(key)\n",
    "        else:\n",
    "            del candidateItemset[key]\n",
    "\n",
    "    finalCounts += list(countCandidates.values())\n",
    "\n",
    "\n",
    "\n",
    "    if len(candidateItemset) == 0:\n",
    "        return frequentItemset, finalCounts\n",
    "    k = 3\n",
    "\n",
    "    while True:\n",
    "        countCandidates = {}\n",
    "        newCandidates = {}\n",
    "        currentSet = list(candidateItemset)\n",
    "        # Candidate Generation\n",
    "        for i in range(0, len(candidateItemset)):\n",
    "            for h in range(i + 1, len(candidateItemset)):\n",
    "                match = True\n",
    "                for x in range(0, len(currentSet[i]) - 2):\n",
    "                    if len(currentSet[i]) != len(currentSet[h]):\n",
    "                        continue\n",
    "                    if currentSet[i][x] != currentSet[h][x]:\n",
    "                        match = False\n",
    "                if match == True:\n",
    "                    newElement = (\n",
    "                        currentSet[i] + \" \" + currentSet[h][len(currentSet[h]) - 1]\n",
    "                    )\n",
    "                    if newElement not in newCandidates:\n",
    "                        L = candidateItemset[currentSet[i]]\n",
    "                        L.append(currentSet[h][len(currentSet[h]) - 1])\n",
    "                        newCandidates[newElement] = L\n",
    "\n",
    "        # Transaction Iteration\n",
    "        newCountCandidates = {}\n",
    "        for key in newCandidates:\n",
    "            for transaction in T:\n",
    "                if len([h for h in newCandidates[key] if h not in transaction]) == 0:\n",
    "                    if key in newCountCandidates:\n",
    "                        newCountCandidates[key] += 1\n",
    "                    else:\n",
    "                        newCountCandidates[key] = 1\n",
    "        # Candidate Pruning\n",
    "        for key in list(newCandidates):\n",
    "            if key in newCountCandidates:\n",
    "                if newCountCandidates[key] < minSupport:\n",
    "                    del newCandidates[key]\n",
    "                    del newCountCandidates[key]\n",
    "                else:\n",
    "                    frequentItemset.append(key)\n",
    "            else:\n",
    "                del newCandidates[key]\n",
    "\n",
    "        finalCounts += list(newCountCandidates.values())\n",
    "\n",
    "        \n",
    "\n",
    "        # If no candidates after pruning, return\n",
    "        if len(newCandidates) == 0:\n",
    "            return frequentItemset, finalCounts\n",
    "        candidateItemset = newCandidates\n",
    "\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emojiset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT maykahangtoran: We really made VP Leni Robr...</td>\n",
       "      <td>ğŸ˜­</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT DEATHBALL13: Meanwhile ğŸ¤¡ğŸ¤¡Joey youâ€™re hiding...</td>\n",
       "      <td>ğŸ¤¡ğŸ¤¡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT minimeuu: JÃ¡ apanhaste COVID!? Me:nÃ£o ğŸ˜¬ RT ...</td>\n",
       "      <td>ğŸ˜¬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT sarinhaavps: JÃ¡ apanhaste COVID!? Me:nÃ£o ğŸ˜¬ ...</td>\n",
       "      <td>ğŸ˜¬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT fann961: 7-day average daily Covid deaths p...</td>\n",
       "      <td>ğŸ‡­ğŸ‡°,ğŸ‡ºğŸ‡¸,ğŸ‡¯ğŸ‡µ,ğŸ‡¬ğŸ‡§,ğŸ‡¨ğŸ‡¦,ğŸ‡¦ğŸ‡º,ğŸ‡¸ğŸ‡¬</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet              Emojiset\n",
       "0  RT maykahangtoran: We really made VP Leni Robr...                     ğŸ˜­\n",
       "1  RT DEATHBALL13: Meanwhile ğŸ¤¡ğŸ¤¡Joey youâ€™re hiding...                    ğŸ¤¡ğŸ¤¡\n",
       "2  RT minimeuu: JÃ¡ apanhaste COVID!? Me:nÃ£o ğŸ˜¬ RT ...                     ğŸ˜¬\n",
       "3  RT sarinhaavps: JÃ¡ apanhaste COVID!? Me:nÃ£o ğŸ˜¬ ...                     ğŸ˜¬\n",
       "4  RT fann961: 7-day average daily Covid deaths p...  ğŸ‡­ğŸ‡°,ğŸ‡ºğŸ‡¸,ğŸ‡¯ğŸ‡µ,ğŸ‡¬ğŸ‡§,ğŸ‡¨ğŸ‡¦,ğŸ‡¦ğŸ‡º,ğŸ‡¸ğŸ‡¬"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"covid.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emoji import UNICODE_EMOJI\n",
    "\n",
    "def extractEmojis(text):\n",
    "    emojis = []\n",
    "\n",
    "    if type(text) != str:\n",
    "        return []\n",
    "    \n",
    "    for word in text.split(\" \"):\n",
    "        if word in UNICODE_EMOJI['en']:\n",
    "            emojis.append(word)\n",
    "        else:\n",
    "            current_emoji = \"\"\n",
    "\n",
    "            for c in range(len(word)):\n",
    "                if word[c] in UNICODE_EMOJI['en']:\n",
    "                    current_emoji += word[c]\n",
    "\n",
    "            if current_emoji != \"\":\n",
    "                emojis.append(current_emoji)\n",
    "                current_emoji = \"\"\n",
    "\n",
    "    return emojis\n",
    "\n",
    "# UNICODE_EMOJI['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emojiset</th>\n",
       "      <th>extracted_emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT maykahangtoran: We really made VP Leni Robr...</td>\n",
       "      <td>ğŸ˜­</td>\n",
       "      <td>[ğŸ˜­]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT DEATHBALL13: Meanwhile ğŸ¤¡ğŸ¤¡Joey youâ€™re hiding...</td>\n",
       "      <td>ğŸ¤¡ğŸ¤¡</td>\n",
       "      <td>[ğŸ¤¡ğŸ¤¡]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT minimeuu: JÃ¡ apanhaste COVID!? Me:nÃ£o ğŸ˜¬ RT ...</td>\n",
       "      <td>ğŸ˜¬</td>\n",
       "      <td>[ğŸ˜¬]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT sarinhaavps: JÃ¡ apanhaste COVID!? Me:nÃ£o ğŸ˜¬ ...</td>\n",
       "      <td>ğŸ˜¬</td>\n",
       "      <td>[ğŸ˜¬]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT fann961: 7-day average daily Covid deaths p...</td>\n",
       "      <td>ğŸ‡­ğŸ‡°,ğŸ‡ºğŸ‡¸,ğŸ‡¯ğŸ‡µ,ğŸ‡¬ğŸ‡§,ğŸ‡¨ğŸ‡¦,ğŸ‡¦ğŸ‡º,ğŸ‡¸ğŸ‡¬</td>\n",
       "      <td>[ğŸ‡­ğŸ‡°, ğŸ‡ºğŸ‡¸, ğŸ‡¯ğŸ‡µ, ğŸ‡¬ğŸ‡§, ğŸ‡¨ğŸ‡¦, ğŸ‡¦ğŸ‡º, ğŸ‡¸ğŸ‡¬]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet              Emojiset  \\\n",
       "0  RT maykahangtoran: We really made VP Leni Robr...                     ğŸ˜­   \n",
       "1  RT DEATHBALL13: Meanwhile ğŸ¤¡ğŸ¤¡Joey youâ€™re hiding...                    ğŸ¤¡ğŸ¤¡   \n",
       "2  RT minimeuu: JÃ¡ apanhaste COVID!? Me:nÃ£o ğŸ˜¬ RT ...                     ğŸ˜¬   \n",
       "3  RT sarinhaavps: JÃ¡ apanhaste COVID!? Me:nÃ£o ğŸ˜¬ ...                     ğŸ˜¬   \n",
       "4  RT fann961: 7-day average daily Covid deaths p...  ğŸ‡­ğŸ‡°,ğŸ‡ºğŸ‡¸,ğŸ‡¯ğŸ‡µ,ğŸ‡¬ğŸ‡§,ğŸ‡¨ğŸ‡¦,ğŸ‡¦ğŸ‡º,ğŸ‡¸ğŸ‡¬   \n",
       "\n",
       "               extracted_emojis  \n",
       "0                           [ğŸ˜­]  \n",
       "1                          [ğŸ¤¡ğŸ¤¡]  \n",
       "2                           [ğŸ˜¬]  \n",
       "3                           [ğŸ˜¬]  \n",
       "4  [ğŸ‡­ğŸ‡°, ğŸ‡ºğŸ‡¸, ğŸ‡¯ğŸ‡µ, ğŸ‡¬ğŸ‡§, ğŸ‡¨ğŸ‡¦, ğŸ‡¦ğŸ‡º, ğŸ‡¸ğŸ‡¬]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['extracted_emojis'] = data['Tweet'].apply(extractEmojis)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              [ğŸ˜­]\n",
       "1                             [ğŸ¤¡ğŸ¤¡]\n",
       "2                              [ğŸ˜¬]\n",
       "3                              [ğŸ˜¬]\n",
       "4     [ğŸ‡­ğŸ‡°, ğŸ‡ºğŸ‡¸, ğŸ‡¯ğŸ‡µ, ğŸ‡¬ğŸ‡§, ğŸ‡¨ğŸ‡¦, ğŸ‡¦ğŸ‡º, ğŸ‡¸ğŸ‡¬]\n",
       "5                              [ğŸ˜…]\n",
       "6                           [ğŸ•¯, ğŸ•¯]\n",
       "7                           [ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£]\n",
       "8                              [ğŸ—£]\n",
       "9                          [ğŸ˜¡â¬‡, ğŸ˜•]\n",
       "10                             [ğŸ¤¬]\n",
       "11                             [ğŸ˜­]\n",
       "12                      [ğŸª™ğŸ™, ğŸ™, ğŸª™]\n",
       "13                             [ğŸ˜­]\n",
       "14                          [ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£]\n",
       "15                             [â–¶]\n",
       "16                      [ğŸ¦ , ğŸ’‰, ğŸ™ŒğŸ»]\n",
       "17                          [ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£]\n",
       "18                            [â˜ğŸ»]\n",
       "19                         [ğŸ˜¡â¬‡, ğŸ˜•]\n",
       "20                        [ğŸ¤¦â™€ğŸ¤¦â™€ğŸ¤¦â™€]\n",
       "21                          [ğŸ¤§, ğŸ’š]\n",
       "22                             [ğŸ’¡]\n",
       "23                         [ğŸš¨, ğŸ¤¬ğŸ¤®]\n",
       "24                     [ğŸ”¬, â¡ï¸, âœï¸]\n",
       "25                             [ğŸ¤®]\n",
       "26                          [ğŸŒ, ğŸ˜·]\n",
       "27                            [ğŸ‘ğŸ¼]\n",
       "28                            [ğŸ–ï¸]\n",
       "29                             [ğŸ¤£]\n",
       "30                            [ğŸ˜­ğŸ˜­]\n",
       "31                             [ğŸ˜­]\n",
       "32                            [ğŸ’‰ğŸ’‰]\n",
       "33                          [ğŸ’•, ğŸ˜ƒ]\n",
       "34                             [ğŸ¤”]\n",
       "35                             [ğŸ˜­]\n",
       "36                             [ğŸ˜­]\n",
       "37                             [ğŸ˜“]\n",
       "38                 [ğŸ‘‡, ğŸ‘‰, ğŸ‘‰, ğŸ‘‰, ğŸ¥]\n",
       "39                             [ğŸ¤¡]\n",
       "40                          [ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£]\n",
       "41                           [ğŸ˜­ğŸ™ğŸ»]\n",
       "42                             [ğŸ’‰]\n",
       "43                             [ğŸ˜]\n",
       "44                            [ğŸ™ğŸ»]\n",
       "45                            [ğŸ“„ğŸ’‰]\n",
       "46                             [ğŸ˜]\n",
       "47                         [ğŸ¤·ğŸ»â€â™‚ï¸]\n",
       "48                 [ğŸ‘‡, ğŸ‘‰, ğŸ‘‰, ğŸ‘‰, ğŸ¥]\n",
       "49                     [ğŸ”¬, â¡ï¸, âœï¸]\n",
       "Name: extracted_emojis, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputList = data['extracted_emojis']\n",
    "inputList.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "setSup = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                [ğŸ˜­]\n",
       "1                               [ğŸ¤¡ğŸ¤¡]\n",
       "2                                [ğŸ˜¬]\n",
       "3                                [ğŸ˜¬]\n",
       "4       [ğŸ‡­ğŸ‡°, ğŸ‡ºğŸ‡¸, ğŸ‡¯ğŸ‡µ, ğŸ‡¬ğŸ‡§, ğŸ‡¨ğŸ‡¦, ğŸ‡¦ğŸ‡º, ğŸ‡¸ğŸ‡¬]\n",
       "                    ...             \n",
       "996                             [ğŸ’‰ğŸ’‰]\n",
       "997                           [â˜‘, â˜‘]\n",
       "998                              [ğŸ‘‘]\n",
       "999                           [âœ…, ğŸ˜·]\n",
       "1000                              []\n",
       "Name: extracted_emojis, Length: 1001, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ğŸ˜­', 'ğŸ¤¡ğŸ¤¡', 'ğŸ˜¬', 'ğŸ‡ºğŸ‡¸', 'ğŸ‡¬ğŸ‡§', 'ğŸ‡¸ğŸ‡¬', 'ğŸ˜…', 'ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£', 'ğŸ—£', 'ğŸ˜¡â¬‡', 'ğŸ˜•', 'ğŸ¤¬', 'ğŸª™ğŸ™', 'ğŸ™', 'ğŸª™', 'â–¶', 'ğŸ¦ ', 'ğŸ’‰', 'ğŸ™ŒğŸ»', 'ğŸ’¡', 'ğŸš¨', 'ğŸ¤¬ğŸ¤®', 'ğŸ”¬', 'â¡ï¸', 'âœï¸', 'ğŸ˜·', 'ğŸ‘ğŸ¼', 'ğŸ–ï¸', 'ğŸ¤£', 'ğŸ˜­ğŸ˜­', 'ğŸ’‰ğŸ’‰', 'ğŸ’•', 'ğŸ˜ƒ', 'ğŸ¤”', 'ğŸ‘‡', 'ğŸ‘‰', 'ğŸ¥', 'ğŸ¤¡', 'ğŸ˜', 'âœ…', 'ğŸ§µ', 'ğŸ™„', 'ğŸ—£ï¸', 'ğŸ˜·ğŸ‘', 'ğŸ˜©', 'ğŸ‘', 'ğŸ¥´', 'ğŸ˜', 'â¤', 'âœˆï¸', 'ğŸ›«', 'ğŸ˜‚', 'ğŸ”¸', 'â„¢', 'ğŸ˜', 'ğŸ‡©ğŸ‡´', 'ğŸ˜³', 'ğŸ˜‰', 'âŒ', 'ğŸ—ï¸', 'ğŸ”´', 'â¡', 'ğŸ¤«', 'ğŸ˜ˆ', 'ğŸ˜¥', 'ğŸ¤¦\\u200dâ™‚ï¸', 'ğŸ›‘', 'ğŸ‡§ğŸ‡·', 'ğŸ˜¡ğŸš©', 'ğŸ˜­ğŸ˜¤', 'ğŸ‘', 'ğŸ‘€', 'ğŸ›¡', 'ğŸ“', 'ğŸ­', 'ğŸŒ', 'ğŸ¤£ğŸ¤£ğŸ¤£', 'ğŸ¥º', 'ğŸ˜”', 'â€¼', 'ğŸ±ğŸ’­', 'ğŸ‘ğŸ½', 'âœ”', 'ğŸ©¹', 'â•', 'ğŸ‘‰ğŸ½', 'ğŸ˜±', 'ğŸ˜Š', 'ğŸ¤¯', 'ğŸ§Ÿ\\u200dâ™‚ï¸', 'ğŸ“¢', 'ğŸ¥ºğŸ¤ğŸ»', 'ğŸ§ª', 'ğŸ“ˆâ¡', 'ğŸ’¢', 'ğŸ˜­ğŸ˜­ğŸ˜­', 'ğŸ¤£ğŸ¤£', 'ğŸš©ğŸ¥°â¤', 'ğŸ‘‡ğŸ½', 'ğŸ•ŠğŸš©ğŸ’‰', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'ğŸ‡ºğŸ‡¦', 'ğŸ˜†', 'â¬‡', 'ğŸ¥', 'ğŸ“Œ', 'ğŸ§¬', 'â™¨', 'ğŸ”¥', 'ğŸ˜', 'ğŸŸ¢', 'ğŸ”¹', 'ğŸ¤¨', 'ğŸ˜… ğŸ¤£ğŸ¤£ğŸ¤£', 'ğŸ˜¡â¬‡ ğŸ˜•', 'ğŸª™ğŸ™ ğŸ™', 'ğŸª™ğŸ™ ğŸª™', 'ğŸ™ ğŸª™', 'ğŸ™ ğŸ™„', 'â–¶ ğŸ”¸', 'ğŸ¦  ğŸ’‰', 'ğŸ¦  ğŸ™ŒğŸ»', 'ğŸ¦  ğŸ¤”', 'ğŸ¦  ğŸ‘ğŸ½', 'ğŸ¦  âœ”', 'ğŸ¦  ğŸ©¹', 'ğŸ¦  â•', 'ğŸ¦  ğŸ‘‰ğŸ½', 'ğŸ’‰ ğŸ™ŒğŸ»', 'ğŸš¨ ğŸ¤¬ğŸ¤®', 'ğŸ”¬ â¡ï¸', 'ğŸ”¬ âœï¸', 'ğŸ”¬ ğŸ§ª', 'ğŸ”¬ ğŸ“ˆâ¡', 'â¡ï¸ âœï¸', 'ğŸ˜· âœ…', 'ğŸ’• ğŸ˜ƒ', 'ğŸ¤” ğŸ‘ğŸ½', 'ğŸ¤” âœ”', 'ğŸ¤” ğŸ©¹', 'ğŸ¤” â•', 'ğŸ¤” ğŸ‘‰ğŸ½', 'ğŸ‘‡ ğŸ‘‰', 'ğŸ‘‡ ğŸ¥', 'ğŸ‘‡ â¡', 'ğŸ‘‡ ğŸ­', 'ğŸ‘‰ ğŸ¥', 'ğŸ‘‰ ğŸ“Œ', 'ğŸ¥ ğŸ”´', 'âœˆï¸ ğŸ›«', 'â„¢ ğŸ˜', 'â¡ ğŸ­', 'ğŸ¤« ğŸ˜ˆ', 'ğŸ‡§ğŸ‡· ğŸ˜¡ğŸš©', 'ğŸ‘ğŸ½ âœ”', 'ğŸ‘ğŸ½ ğŸ©¹', 'ğŸ‘ğŸ½ â•', 'ğŸ‘ğŸ½ ğŸ‘‰ğŸ½', 'âœ” ğŸ©¹', 'âœ” â•', 'âœ” ğŸ‘‰ğŸ½', 'ğŸ©¹ â•', 'ğŸ©¹ ğŸ‘‰ğŸ½', 'â• ğŸ‘‰ğŸ½', 'ğŸ§ª ğŸ“ˆâ¡', 'ğŸš©ğŸ¥°â¤ ğŸ‘‡ğŸ½', 'ğŸš©ğŸ¥°â¤ ğŸ•ŠğŸš©ğŸ’‰', 'ğŸ‘‡ğŸ½ ğŸ•ŠğŸš©ğŸ’‰', 'â™¨ ğŸ”¥']\n",
      "[116, 10, 12, 9, 3, 3, 10, 64, 32, 15, 15, 7, 4, 21, 4, 12, 13, 36, 3, 8, 16, 9, 8, 15, 6, 24, 3, 3, 16, 4, 24, 5, 6, 20, 20, 39, 10, 12, 6, 37, 12, 21, 3, 6, 3, 7, 5, 5, 4, 3, 3, 16, 82, 12, 12, 4, 4, 12, 13, 5, 15, 9, 5, 5, 3, 3, 5, 5, 5, 3, 3, 7, 4, 6, 3, 3, 4, 5, 4, 6, 3, 3, 6, 6, 6, 6, 3, 3, 3, 3, 4, 6, 5, 4, 3, 4, 3, 3, 3, 3, 3, 5, 3, 4, 3, 7, 6, 4, 7, 3, 10, 4, 3, 3, 15, 4, 4, 4, 6, 11, 3, 3, 3, 3, 6, 6, 6, 6, 3, 9, 4, 4, 4, 4, 4, 7, 5, 3, 3, 3, 3, 3, 4, 4, 3, 3, 4, 4, 6, 3, 12, 3, 3, 5, 3, 3, 3, 3, 6, 6, 6, 6, 6, 6, 4, 3, 3, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "x, counts = procedureApriori(inputList, setSup)\n",
    "print(x)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_new_x = []\n",
    "new_x = []\n",
    "for i in x:\n",
    "    frozen_new_x.append(frozenset([k for k in i.split(\" \")]))\n",
    "    new_x.append([k for k in i.split(\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = pd.DataFrame()\n",
    "frequent_itemsets[\"itemsets\"] = frozen_new_x\n",
    "frequent_itemsets[\"support\"] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemsets</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ğŸ˜­)</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(ğŸ¤¡ğŸ¤¡)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(ğŸ˜¬)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(ğŸ‡ºğŸ‡¸)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(ğŸ‡¬ğŸ‡§)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  itemsets  support\n",
       "0      (ğŸ˜­)      116\n",
       "1     (ğŸ¤¡ğŸ¤¡)       10\n",
       "2      (ğŸ˜¬)       12\n",
       "3     (ğŸ‡ºğŸ‡¸)        9\n",
       "4     (ğŸ‡¬ğŸ‡§)        3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemsets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = association_rules(frequent_itemsets, support_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = []\n",
    "for l in range(len(r[\"antecedents\"].values)):\n",
    "    rules.append([list(r[\"antecedents\"][l])[0], list(r[\"consequents\"][l])[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ğŸ˜…', 'ğŸ¤£ğŸ¤£ğŸ¤£'], ['ğŸ˜¡â¬‡', 'ğŸ˜•'], ['ğŸª™ğŸ™', 'ğŸ™'], ['ğŸª™ğŸ™', 'ğŸª™'], ['ğŸ™', 'ğŸª™'], ['ğŸ™', 'ğŸ™„'], ['â–¶', 'ğŸ”¸'], ['ğŸ¦ ', 'ğŸ’‰'], ['ğŸ¦ ', 'ğŸ™ŒğŸ»'], ['ğŸ¦ ', 'ğŸ¤”'], ['ğŸ¦ ', 'ğŸ‘ğŸ½'], ['ğŸ¦ ', 'âœ”'], ['ğŸ¦ ', 'ğŸ©¹'], ['ğŸ¦ ', 'â•'], ['ğŸ¦ ', 'ğŸ‘‰ğŸ½'], ['ğŸ’‰', 'ğŸ™ŒğŸ»'], ['ğŸš¨', 'ğŸ¤¬ğŸ¤®'], ['ğŸ”¬', 'â¡ï¸'], ['ğŸ”¬', 'âœï¸'], ['ğŸ”¬', 'ğŸ§ª'], ['ğŸ”¬', 'ğŸ“ˆâ¡'], ['â¡ï¸', 'âœï¸'], ['ğŸ˜·', 'âœ…'], ['ğŸ’•', 'ğŸ˜ƒ'], ['ğŸ¤”', 'ğŸ‘ğŸ½'], ['ğŸ¤”', 'âœ”'], ['ğŸ¤”', 'ğŸ©¹'], ['ğŸ¤”', 'â•'], ['ğŸ¤”', 'ğŸ‘‰ğŸ½'], ['ğŸ‘‡', 'ğŸ‘‰'], ['ğŸ‘‡', 'ğŸ¥'], ['ğŸ‘‡', 'â¡'], ['ğŸ‘‡', 'ğŸ­'], ['ğŸ‘‰', 'ğŸ¥'], ['ğŸ‘‰', 'ğŸ“Œ'], ['ğŸ¥', 'ğŸ”´'], ['âœˆï¸', 'ğŸ›«'], ['â„¢', 'ğŸ˜'], ['â¡', 'ğŸ­'], ['ğŸ¤«', 'ğŸ˜ˆ'], ['ğŸ‡§ğŸ‡·', 'ğŸ˜¡ğŸš©'], ['ğŸ‘ğŸ½', 'âœ”'], ['ğŸ‘ğŸ½', 'ğŸ©¹'], ['ğŸ‘ğŸ½', 'â•'], ['ğŸ‘ğŸ½', 'ğŸ‘‰ğŸ½'], ['âœ”', 'ğŸ©¹'], ['âœ”', 'â•'], ['âœ”', 'ğŸ‘‰ğŸ½'], ['ğŸ©¹', 'â•'], ['ğŸ©¹', 'ğŸ‘‰ğŸ½'], ['â•', 'ğŸ‘‰ğŸ½'], ['ğŸ§ª', 'ğŸ“ˆâ¡'], ['ğŸš©ğŸ¥°â¤', 'ğŸ‘‡ğŸ½'], ['ğŸš©ğŸ¥°â¤', 'ğŸ•ŠğŸš©ğŸ’‰'], ['ğŸ‘‡ğŸ½', 'ğŸ•ŠğŸš©ğŸ’‰'], ['â™¨', 'ğŸ”¥']]\n"
     ]
    }
   ],
   "source": [
    "new_rules = []\n",
    "\n",
    "for i in new_x:\n",
    "    for rule in rules:\n",
    "        before = rule[0]\n",
    "        after = rule[1]\n",
    "        before_idx = None\n",
    "        after_idx = None\n",
    "        for item in i:\n",
    "            if item == before:\n",
    "                if before_idx == None:\n",
    "                    before_idx = i.index(item)\n",
    "            elif item == after:\n",
    "                if after_idx == None:\n",
    "                    after_idx = i.index(item)\n",
    "        if before_idx != None and after_idx != None:\n",
    "            if before_idx < after_idx:\n",
    "                if rule not in new_rules:\n",
    "                    new_rules.append(rule)\n",
    "print(new_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
